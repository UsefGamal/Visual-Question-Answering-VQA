{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### all imports","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.applications.vgg19 import VGG19 , preprocess_input\nfrom keras.utils import load_img, img_to_array\nfrom tqdm import tqdm\nimport re\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:40:29.326061Z","iopub.execute_input":"2023-05-13T21:40:29.326431Z","iopub.status.idle":"2023-05-13T21:40:29.334928Z","shell.execute_reply.started":"2023-05-13T21:40:29.326402Z","shell.execute_reply":"2023-05-13T21:40:29.333874Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import json #to create dataset metadata json file","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:40:31.502449Z","iopub.execute_input":"2023-05-13T21:40:31.502944Z","iopub.status.idle":"2023-05-13T21:40:31.508812Z","shell.execute_reply.started":"2023-05-13T21:40:31.502902Z","shell.execute_reply":"2023-05-13T21:40:31.507957Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### initialize a generator for the validation images \n#### Note: change train2014 for the train images","metadata":{}},{"cell_type":"code","source":"# Define paths to dataset and output files\ndata_dir = \"/kaggle/input/visual-question-answering/\"\noutput_dir = \"/kaggle/working/\"\nimage_dir = os.path.join(data_dir, \"val2014\")\noutput_file = os.path.join(output_dir, \"val_features.npy\")\n\n# Define a data generator to preprocess the images\ntarget_size = (224, 224)\ndatagen = ImageDataGenerator(preprocessing_function=preprocess_input)\ngenerator = datagen.flow_from_directory(\n    image_dir,\n    target_size=target_size,\n    batch_size=32,\n    class_mode=None,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:40:37.589592Z","iopub.execute_input":"2023-05-13T21:40:37.590011Z","iopub.status.idle":"2023-05-13T21:40:56.627744Z","shell.execute_reply.started":"2023-05-13T21:40:37.589977Z","shell.execute_reply":"2023-05-13T21:40:56.626664Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Found 40504 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### load VGG19 and extract images features","metadata":{}},{"cell_type":"code","source":"# Create an VGG19 model to extract image features\nbase_model = VGG19(weights='imagenet')","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:41:42.061224Z","iopub.execute_input":"2023-05-13T21:41:42.061779Z","iopub.status.idle":"2023-05-13T21:41:50.149687Z","shell.execute_reply.started":"2023-05-13T21:41:42.061740Z","shell.execute_reply":"2023-05-13T21:41:50.148739Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n574710816/574710816 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Model(inputs=base_model.input, outputs=base_model.get_layer('flatten').output)","metadata":{"execution":{"iopub.status.busy":"2023-05-13T21:45:10.082089Z","iopub.execute_input":"2023-05-13T21:45:10.082459Z","iopub.status.idle":"2023-05-13T21:45:10.093152Z","shell.execute_reply.started":"2023-05-13T21:45:10.082429Z","shell.execute_reply":"2023-05-13T21:45:10.091976Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Extract image features for each image in the training set\ntrain_features = []\nfor i in tqdm(range(len(generator))):\n    batch = generator.next()\n    features = model.predict_on_batch(batch)\n    train_features.append(features)\n\n# Concatenate and reshape the extracted features into a numpy array\ntrain_features = np.concatenate(train_features)\ntrain_features = train_features.reshape((len(generator.filenames), -1))\n\n# Save the extracted features to a numpy file\nnp.save(output_file, train_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### save features with IDs in a dictionary in a pkl file","metadata":{}},{"cell_type":"code","source":"# add ids to features\nimg_ids = np.array([int(re.search(\"[0-9][0-9][0-9][0-9][0-9]+\", gen).group()) for gen in generator.filenames])\nimage_features = {}\nfor i in range(len(img_ids)):\n    image_features[img_ids[i]]= train_features[i]","metadata":{"execution":{"iopub.status.busy":"2023-05-09T18:20:43.456636Z","iopub.execute_input":"2023-05-09T18:20:43.457029Z","iopub.status.idle":"2023-05-09T18:20:43.652365Z","shell.execute_reply.started":"2023-05-09T18:20:43.456996Z","shell.execute_reply":"2023-05-09T18:20:43.65141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save dictionary to test_image_features.pkl file\nwith open('test_image_features.pkl', 'wb') as fp:\n    pickle.dump(image_features, fp)\n    print('dictionary saved successfully to file')","metadata":{"execution":{"iopub.status.busy":"2023-05-09T18:21:28.844212Z","iopub.execute_input":"2023-05-09T18:21:28.84459Z","iopub.status.idle":"2023-05-09T18:21:30.212984Z","shell.execute_reply.started":"2023-05-09T18:21:28.84456Z","shell.execute_reply":"2023-05-09T18:21:30.211466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# end","metadata":{}}]}
